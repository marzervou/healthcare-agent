{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8e46472-fe71-4f5a-b3b7-18ea6151d8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade \"mlflow[databricks]>=3.1.0\" openai \"databricks-connect>=16.1\"\n",
    "%pip install faker\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a2b2c0c-4f49-4430-a7ca-6dacf736cbe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import mlflow\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03fe3649-f325-4040-af87-4078fdf9fa84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "faker = faker.Faker()\n",
    "def random_datetime(start, end):\n",
    "    return start + timedelta(seconds=random.randint(0, int((end - start).total_seconds())))\n",
    "\n",
    "num_records = 200\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2025, 6, 1)\n",
    "\n",
    "visit_data = []\n",
    "\n",
    "print(f\"Generating {num_records} synthetic patient visits...\")\n",
    "for i in range(num_records):\n",
    "    patient_name = faker.name()\n",
    "    patient_id = faker.uuid4()\n",
    "    visit_date = random_datetime(start_date, end_date)\n",
    "    doctor_name = faker.name()\n",
    "    department = random.choice([\"Cardiology\", \"Neurology\", \"Oncology\", \"Orthopedics\", \"General Medicine\"])\n",
    "\n",
    "    record = {\n",
    "        \"patient_id\": str(patient_id),\n",
    "        \"patient_name\": patient_name,\n",
    "        \"visit_datetime\": visit_date.isoformat(),\n",
    "        \"doctor_name\": doctor_name,\n",
    "        \"department\": department\n",
    "    }\n",
    "    visit_data.append(record)\n",
    "\n",
    "# Convert to DataFrame\n",
    "visit_df = pd.DataFrame(visit_data)\n",
    "\n",
    "# Write patient visit data to table\n",
    "visit_spark_df = spark.createDataFrame(visit_df)\n",
    "visit_spark_df.write.mode(\"overwrite\").saveAsTable(\"mzervou.healthcare.synthetic_patient_visits\")\n",
    "\n",
    "print(\"✅ Patient visit data written to table: mzervou.healthcare.synthetic_patient_visits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ab5505d-bc08-44c7-8e47-9acff1a50727",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "catalog = \"mzervou\"\n",
    "schema = \"healthcare\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54ab04b5-719b-4535-a5fa-2ae7a01001d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Limit if testing first\n",
    "# df_visits = visit_spark_df.limit(5)\n",
    "\n",
    "# Define your prompt template\n",
    "prompt_template = \"\"\"You are a doctor named {doctor_name} in the {department} department. You just completed a consultation with patient {patient_name} on {visit_datetime}. Record an audio note in natural, spoken style summarizing the encounter. Include symptoms, findings, impressions, and plan. Do not use SOAP format. Begin with: 'Okay, today I saw patient {patient_name} ...'\"\"\"\n",
    "\n",
    "# Build ai_query column\n",
    "df_transcripts = visit_spark_df.withColumn(\n",
    "    \"audio_transcript\",\n",
    "    expr(\n",
    "        f\"\"\"\n",
    "        ai_query(\n",
    "            '{model_name}',\n",
    "            concat(\n",
    "                'You are a doctor named ', doctor_name,\n",
    "                ' in the ', department, ' department. You just completed a consultation with patient ', patient_name,\n",
    "                ' on ', visit_datetime, '. Record an audio note in natural, spoken style summarizing the encounter. Include symptoms, findings, impressions, and plan. Do not use SOAP format. Begin with: \\\\'Okay, today I saw patient ', patient_name, ' ...\\\\''\n",
    "            )\n",
    "        )\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save to target table\n",
    "df_transcripts.write.mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.synthetic_audio_transcripts\")\n",
    "\n",
    "print(f\"✅ Audio transcripts written using ai_query() to table: {catalog}.{schema}.synthetic_audio_transcripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9c83f00-aeb2-4f66-896b-b0647dc34369",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1. Data Generation - Unstructured Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
